import os
import json
import sqlite3
import glob
import pprint
import random
from datetime import datetime, timedelta

# # âœ… 0.1. ë£¨íŠ¸ í™•ì¸
# import os, json, glob
# source_id = 200001
# classify_dir = "./Data/Classify"

# paths = glob.glob(os.path.join(classify_dir, f"01_ë¶„ë¥˜_{source_id}_*.json"))
# print("ì°¾ì€ íŒŒì¼:", paths)

# for p in paths:
#     with open(p, encoding='utf-8') as f:
#         data = json.load(f)
#     if isinstance(data, list):
#         data = data[0]
#     print("---", os.path.basename(p))
#     print("task_category -->", data.get("task_category"))
#     print("output        -->", data.get("output"))

# # âœ… 0.15. ë£¨íŠ¸ ê³ ì³¤ì–´ ë‹¤ì‹œí™•ì¸
# src = "./Data/Classify/01_ë¶„ë¥˜_200001_1.json"   # í™•ì¸í•  íŒŒì¼ ê²½ë¡œ

# with open(src, encoding="utf-8") as f:
#     data = json.load(f)

# print("ğŸ‘‰ ìµœìƒë‹¨ íƒ€ì…:", type(data).__name__)
# if isinstance(data, list):
#     print("ğŸ‘‰ ë¦¬ìŠ¤íŠ¸ ê¸¸ì´ :", len(data))
#     data = data[0]            # ë³´í†µ í•œ ë©ì–´ë¦¬ì´ë¯€ë¡œ ë¦¬ìŠ¤íŠ¸ ì²« ìš”ì†Œë§Œ ë³´ê¸°
#     print("\n[0] ìš”ì†Œ íƒ€ì… :", type(data).__name__)

# print("\nğŸ‘‰ ìµœìƒë‹¨ í‚¤ ëª©ë¡")
# pprint.pprint(list(data.keys())[:10])          # ë§ìœ¼ë©´ ì• 10ê°œë§Œ

# # âœ… 0.2. ë°ì´í„° ì¶œë ¥ í™•ì¸
# source_id = 200001
# classify_dir = "./Data/Classify"

# # ë‹¤ì„¯ ê°œ ì¹´í…Œê³ ë¦¬ â†’ tickets ì¹¼ëŸ¼ ë§¤í•‘
# need = {
#     "ìƒë‹´ ì£¼ì œ": "category",
#     "ìƒë‹´ ìš”ê±´": "scope",
#     "ìƒë‹´ ë‚´ìš©": "type",
#     "ìƒë‹´ ì‚¬ìœ ": "cause",
#     "ìƒë‹´ ê²°ê³¼": "result",
# }

# # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
# result = {v: None for v in need.values()}

# # í•´ë‹¹ source_idì— ëŒ€í•œ ëª¨ë“  ë¶„ë¥˜ JSON ìˆœíšŒ
# for path in glob.glob(os.path.join(classify_dir, f"01_ë¶„ë¥˜_{source_id}_*.json")):
#     with open(path, encoding="utf-8") as f:
#         data = json.load(f)
#     if isinstance(data, list):
#         data = data[0]

#     task_cat = data.get("task_category")
#     if task_cat in need:
#         result[need[task_cat]] = data.get("output", "").strip()

# # ì˜¤ë¥˜ ê²€ì¦ â”€ í•˜ë‚˜ë¼ë„ ë¹ ì ¸ ìˆìœ¼ë©´ ë©”ì‹œì§€, ì•„ë‹ˆë©´ ê°’ ì¶œë ¥
# if None in result.values():
#     missing = [k for k, v in result.items() if v is None]
#     print(f"[ERROR] ëˆ„ë½ëœ í•­ëª© â†’ {', '.join(missing)}")
# else:
#     print("=== source_id 200001 í‹°ì¼“ ì…ë ¥ ì˜ˆì • ê°’ ===")
#     for k, v in result.items():
#         print(f"{k:<8} : {v}")


# âœ… 1. í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸° (source_id â†” phone ë§¤í•‘ìš©)
def load_clients_info(clients_db_path):
    conn = sqlite3.connect(clients_db_path)
    cursor = conn.cursor()
    cursor.execute("SELECT source_id, phone FROM clients WHERE source_id IS NOT NULL AND phone IS NOT NULL")
    result = {int(row[0]): row[1] for row in cursor.fetchall()}
    conn.close()
    return result

# âœ… 2. ê° source_idì˜ ìµœì‹  ìƒë‹´ ì‹œê°„ ê°€ì ¸ì˜¤ê¸° (conversation_summaryì—ì„œ)
def get_latest_updated_at(chats_db_path):
    conn = sqlite3.connect(chats_db_path)
    cursor = conn.cursor()
    cursor.execute("""
        SELECT source_id, MAX(version), MAX(updated_at) 
        FROM conversation_summary 
        GROUP BY source_id
    """)
    result = {int(row[0]): row[2] for row in cursor.fetchall()}
    conn.close()
    return result

# âœ… 3. ë¶„ë¥˜ JSONì—ì„œ task_categoryì— ë§ëŠ” í•­ëª© ì¶”ì¶œ
def extract_classification_fields(source_id, classify_dir):
    """source_id ì˜ ëª¨ë“  01_ë¶„ë¥˜ JSONì„ ì¬ê·€ íƒìƒ‰í•˜ì—¬
       5ê°œ ì¹¼ëŸ¼(categoryÂ·scopeÂ·typeÂ·causeÂ·result)ì„ ì±„ì›Œì„œ ë°˜í™˜"""
    
    # â‘  ê²°ê³¼ ê·¸ë¦‡
    need_map = {
        "ìƒë‹´ ì£¼ì œ":  "category",
        "ìƒë‹´ ìš”ê±´":  "scope",
        "ìƒë‹´ ë‚´ìš©":  "type",
        "ìƒë‹´ ì‚¬ìœ ":  "cause",
        "ìƒë‹´ ê²°ê³¼":  "result",
    }
    result = {v: None for v in need_map.values()}
    
    # â‘¡ ì¬ê·€ íƒìƒ‰ í•¨ìˆ˜
    def walk(node):
        if isinstance(node, dict):
            if "task_category" in node and "output" in node:
                tc  = node["task_category"]
                out = str(node["output"]).strip()
                if tc in need_map and result[need_map[tc]] is None:
                    result[need_map[tc]] = out
            for v in node.values():
                walk(v)
        elif isinstance(node, list):
            for item in node:
                walk(item)
    
    # â‘¢ í•´ë‹¹ source_id ì˜ ëª¨ë“  01_ë¶„ë¥˜ íŒŒì¼ì„ ìˆœíšŒÂ·íƒìƒ‰
    pattern = os.path.join(classify_dir, f"01_ë¶„ë¥˜_{source_id}_*.json")
    for path in glob.glob(pattern):
        with open(path, encoding="utf-8") as f:
            data = json.load(f)
        walk(data)
    
    return result
# ì²´í¬
# fields = extract_classification_fields(200001, "./Data/Classify")
# print(fields)

# âœ… 4. ìƒíƒœ(status)ë¥¼ í™•ë¥ ì— ë”°ë¼ ìƒì„±
def generate_status():
    r = random.random()
    if r < 0.0005:
        return "ëŒ€ê¸°ì¤‘"
    elif r < 0.001:
        return "ì²˜ë¦¬ì¤‘"
    return "ì™„ë£Œ"

# âœ… 5. ìƒì„± ì‹œê°„ ë° ìƒíƒœ ë³€ê²½ ì‹œê°„ ìƒì„±
def generate_timestamps(base_time_str):
    base_time = datetime.strptime(base_time_str, "%Y-%m-%d %H:%M:%S")
    created_at = base_time + timedelta(seconds=random.randint(1, 10))
    updated_at = created_at + timedelta(hours=random.randint(13, 48), minutes=random.randint(0, 59))
    return created_at.strftime("%Y-%m-%d %H:%M:%S"), updated_at.strftime("%Y-%m-%d %H:%M:%S")

# âœ… 6. tickets í…Œì´ë¸” ì´ˆê¸°í™” í›„ INSERT
def populate_tickets(clients_db, chats_db, tickets_db, classify_dir):
    clients = load_clients_info(clients_db)
    latest_times = get_latest_updated_at(chats_db)

    conn = sqlite3.connect(tickets_db)
    cursor = conn.cursor()
    cursor.execute("DELETE FROM tickets")

    ticket_id = 1

    for source_id, phone in clients.items():
        if source_id not in latest_times:
            continue

        classification = extract_classification_fields(source_id, classify_dir)
        if not all(classification.values()):
            print(f"[SKIP] source_id={source_id} â†’ ì¼ë¶€ ë¶„ë¥˜ ì •ë³´ ì—†ìŒ")
            continue

        created_at, updated_at = generate_timestamps(latest_times[source_id])
        status = generate_status()

        cursor.execute("""
            INSERT INTO tickets (
                ticket_id, source_id, phone, category, scope, type, cause, result, 
                status, created_at, updated_at
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, (
            ticket_id, source_id, phone,
            classification["category"], classification["scope"], classification["type"],
            classification["cause"], classification["result"],
            status, created_at, updated_at
        ))

        print(f"[OK] source_id={source_id} â†’ ticket_id={ticket_id}")
        ticket_id += 1

    conn.commit()
    conn.close()

# âœ… 7. ì‹¤í–‰ ì‹œì‘ì 
if __name__ == "__main__":
    # ê²½ë¡œ ì„¤ì •
    clients_db_path = "./clientsdb/clients.db"
    chats_db_path = "./chatsdb/chats.db"
    tickets_db_path = "./ticketsdb/Tickets.db"
    classify_dir = "./Data/Classify"

    # í‹°ì¼“ ìƒì„± ì‹¤í–‰
    populate_tickets(clients_db_path, chats_db_path, tickets_db_path, classify_dir)
